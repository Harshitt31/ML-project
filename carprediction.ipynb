{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBEIabjk7VF3"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Car data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "rX2MCSXT7ZX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "NIXclMQa7ZaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Seller_Type'].unique())\n",
        "print(df['Fuel_Type'].unique())\n",
        "print(df['Transmission'].unique())\n",
        "print(df['Owner'].unique())"
      ],
      "metadata": {
        "id": "WReK2x8t7Zc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking the missing / Null values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "o9ugu7zw7ZfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "8cLEk9ZN7Zhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset=df[['Year','Selling_Price','Present_Price','Kms_Driven','Fuel_Type','Seller_Type','Transmission','Owner']]"
      ],
      "metadata": {
        "id": "gAX1ZeEi7Zjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset.head()"
      ],
      "metadata": {
        "id": "1-mA5HAV7ZmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the age of the cars\n",
        "final_dataset['no_year']=final_dataset['Current_year']- final_dataset['Year']"
      ],
      "metadata": {
        "id": "5HWYY3n67Zp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset.head()"
      ],
      "metadata": {
        "id": "gJL3atVM7Zsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since now i got the no of yaers i don't need the yaers and current years\n",
        "final_dataset.drop('Year', axis=1, inplace=True)\n",
        "final_dataset.drop('Current_year', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "j-iywFms7ZvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset.head()"
      ],
      "metadata": {
        "id": "k_gfPo8i7Zx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset=pd.get_dummies(final_dataset,drop_first=True)"
      ],
      "metadata": {
        "id": "leoN1ZLf7Z0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's get the dataset\n",
        "final_dataset.head()"
      ],
      "metadata": {
        "id": "81-ZasDT7Z3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Corelation\n",
        "final_dataset.corr()"
      ],
      "metadata": {
        "id": "a2lk9fcE7Z6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "GpV5Ohws7Z9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(final_dataset)"
      ],
      "metadata": {
        "id": "-_8AX93O7aAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "dzfBjNZc8PBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_mat = final_dataset.corr()\n",
        "top_corr_featues = corr_mat.index\n",
        "plt.figure(figsize=(20,20))\n",
        "g=sns.heatmap(final_dataset[top_corr_featues].corr(),annot=True,cmap=\"RdYlGn\")"
      ],
      "metadata": {
        "id": "NhPZ4LQk8PMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_dataset.columns)"
      ],
      "metadata": {
        "id": "1-FkFRQl8Z2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting my Indepenedent and Dependent Features\n",
        "X = final_dataset.drop('Selling_Price', axis=1)\n",
        "\n",
        "# Extracting the dependent variable\n",
        "y = final_dataset['Selling_Price']"
      ],
      "metadata": {
        "id": "EbV2K6hA8Z5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "i9seC98q8Z8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "Ox_rSYMa8hDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Trying to find out the important features\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "model = ExtraTreesRegressor()\n",
        "model.fit(X , y)"
      ],
      "metadata": {
        "id": "JT2Dz_Ad8hGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.feature_importances_)"
      ],
      "metadata": {
        "id": "hchtqbpr8hKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot graph of feature importances for better visualization\n",
        "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(5).plot(kind='barh')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OFQuInom8oi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "7LCGOrNc8olP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "v7xW1Bpk8onN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "uJIV0FMB8opO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestRegressor()"
      ],
      "metadata": {
        "id": "GGcLc03z8371"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
        "print(n_estimators)\n",
        "\n",
        "# Selecting different Estimators from 100 to 1200\n",
        "# 12 equally spaced values between 100 and 1200.\n",
        "# This list defines the number of trees in the random forest"
      ],
      "metadata": {
        "id": "Sq44wWJp83-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In this code, you are preparing to perform hyperparameter tuning using RandomizedSearchCV to find the optimal parameters for a machine learning model, likely a Random Forest or Extra Trees model. Here's a detailed explanation of each part:\n",
        "# Randomized Search Cross-Validation (RandomizedSearchCV)\n",
        "# RandomizedSearchCV is used to search through a subset of hyperparameter combinations to find the best set of parameters for your model. It selects a random combination of hyperparameters at each iteration, which makes it faster than an exhaustive search like GridSearchCV.\n",
        "\n",
        "\n",
        "\n",
        "#Randomized Search CV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
        "\n",
        "# This determines how many features are considered at each split in the trees.\n",
        "max_features = [None, 'sqrt']\n",
        "\n",
        "# Maximum number of levels in tree : Defines the maximum depth of each tree, which limits how deep the trees can grow.\n",
        "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
        "# max_depth.append(None)\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10, 15, 100]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 5, 10]"
      ],
      "metadata": {
        "id": "EGBBYogZ84AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is creating a dictionary called random_grid that stores the different hyperparameters and their possible values for tuning the model. This grid will later be passed into RandomizedSearchCV for hyperparameter optimization.\n",
        "\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf}\n"
      ],
      "metadata": {
        "id": "uAT4tXT_84Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor()"
      ],
      "metadata": {
        "id": "s5stwJEk84Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)"
      ],
      "metadata": {
        "id": "rK4p5Com84G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_random.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "WQ4TUEJm9I-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=rf_random.predict(X_test)"
      ],
      "metadata": {
        "id": "vAJLVN3o9JAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "sTpv8B4Y9JCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
      ],
      "metadata": {
        "id": "0pCkNlfP9JE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# open a file, where you ant to store the data\n",
        "file = open('random_forest_regression_model.pkl', 'wb')\n",
        "\n",
        "# dump information to that file\n",
        "pickle.dump(rf_random, file)"
      ],
      "metadata": {
        "id": "_Rue6RKj9JG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('random_forest_regression_model.pkl', 'rb') as file:\n",
        "    content = file.read()\n",
        "    print(content)\n"
      ],
      "metadata": {
        "id": "4lvvwdyA9JJL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}